<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <title>Abandono de clientes</title>
    <!-- Estilos b√°sicos -->
    <style>
        body {
            font-family: Arial, sans-serif;
            background: #f4f4f4;
            padding: 20px;
        }
        .code-container {
            background: #2d2d2d;
            color: #f8f8f2;
            padding: 15px;
            border-radius: 8px;
            overflow-x: auto;
            font-size: 14px;
            line-height: 1.5;
        }
        pre {
            margin: 0;
        }
    </style>
    <!-- Librer√≠a Prism.js para resaltado -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel<h1>Ejemplo de c√≥digo PySpark</h1>
</head>
   
<h1 style="color: #259B88;"> Abandono de clientes de empresa de telecomunicaciones </h1>
<h2 style="color: #259B88;"> Contexto </h2>
<strong>Causas principales del abandono de clientes</strong>
<ul>
   <li>Mal servicio: Experiencias negativas repetidas con el servicio al cliente son una raz√≥n principal para buscar la competencia.</li>
   <li>Expectativas incumplidas: La empresa no cumple con lo que prometi√≥ a trav√©s de sus productos o servicios.</li>
   <li>Falta de personalizaci√≥n: Los clientes se van si no reciben un trato y ofertas adaptadas a sus necesidades e historial.</li>
   <li>Competencia superior: Los clientes pueden irse si la competencia ofrece algo mejor o m√°s atractivo en ese momento.</li>
   <li>Factores externos: Crisis econ√≥micas o dificultades financieras personales pueden llevar a los clientes a reducir gastos. </li>
</ul>
<br/>
    <img src="fidelizacion.png" />
<br/>
<h2 style="color: #259B88;"> Secciones del Sprint 1 </h2>
<h2 style="color: #259B88;">Secci√≥n 1: Definici√≥n del Problema </h2>
<h3 style="color: #004B5F;">1. Identificar el Problema de Negocio: </h3>
<h4 style="color: #004B5F;">Contexto del problema:</h4>
<ul>
   <li>Total de clientes: 7,043</li>
   <li>Tasa de abandono actual: 26.54%</li>
   <li>Ingreso promedio mensual por cliente: $64.76</li>
   <li>P√©rdida anual estimada: $1,452,475.24</li>
   <li>Clientes que abandonan mensualmente: 1869</li>
</ul>
<h4 style="color: #004B5F;">Impacto:</h4> 
<strong>
‚ÄúLa empresa enfrenta una rotaci√≥n del 26.5% de su base de clientes, esto representa una p√©rdida anual estimada de $1,452,475.24 y de aqu√≠ es que surge la necesidad cr√≠tica de implementar estrategias de fidelizaci√≥n de clientes‚Äù   
</strong>
<h3 style="color: #004B5F;">2. Establecer Objetivos Anal√≠ticos:</h3>
<ul>
   <li>Predecir clientes con alta probabilidad de abandono en los pr√≥ximos 30 d√≠as</li>
   <li>Alcanzar recall del 80% y precisi√≥n del 75% en la detecci√≥n de abandono</li>
   <li>Utilizando datos hist√≥ricos de comportamiento y contratos</li>
   <li>Reducir la tasa de abandono en al menos 15% en 6 meses</li>
   <li>Implementar el modelo en producci√≥n en 8 semanas</li>
</ul>

<h3 style="color: #004B5F;">3. Delimitar el Alcance: </h3>
<h4 style="color: #004B5F;">Variables objetivo:</h4>
<ul>
   <li>Variable dependiente: Abandono (binaria - Yes/No)</li>
   <li>Horizonte temporal: Pr√≥ximos 30 d√≠as</li>
</ul>
<h4 style="color: #004B5F;">Variables predictoras disponibles:</h4>
<ul>
   <li><b><span style="color: #259B88;">Demogr√°ficas:</span></b> 4 variables</li>
   <li><b><span style="color: #259B88;">Servicios:</span></b> 4 variables</li>
   <li><b><span style="color: #259B88;">Contrato y facturaci√≥n:</span></b> 6 variables</li>
    <li><b><span style="color: #259B88;">Otras:</span></b> 3 variables</li>
</ul>
<h4 style="color: #004B5F;">Restricciones identificadas:</h4>
<ul>
   <li><b><span style="color: #259B88;">√âticas:</span></b> Datos anonimizados, sin informaci√≥n personal sensible</li>
   <li><b><span style="color: #259B88;">T√©cnicas:</span></b> Python, scikit-learn, 8GB RAM m√≠nimo y 16 GB de RAM ideal</li>
   <li><b><span style="color: #259B88;">Temporales:</span></b> 4 semanas para desarrollo del modelo</li>
   <li><b><span style="color: #259B88;">Datos:</span></b> Dataset balanceado artificialmente para entrenamiento</li>
</ul>
<h3 style="color: #004B5F;">4. Formular Hip√≥tesis Iniciales:</h3>
<h4 style="color: #004B5F;">Hip√≥tesis principales:</h4>
<ol>
   <li>
        H0: Un modelo de prediccion permite determinar la probabilidad de abandono a partir de caracteristicas demograficas y de servicio de un cliente   
   </li>
   <li>
        H2: Un modelo de prediccion no permite determinar la probabilidad de abandono a partir de caracteristicas demograficas y de servicio de un cliente
   </li>
  
</ol>
<h3 style="color: #004B5F;">5. Criterio de √âxito:</h3>
<h3 style="color: #004B5F;">Criterios de √©xito del modelo:</h3>
<ul>
   <li>Recall: 0.80</li>
   <li>Precision: 0.75</li>
   <li>AUC-ROC: 0.85</li>
   <li>F1-Score: 0.77</li>
   <li>Reducci√≥n_abandono: 15%</li>
   <li>ROI_minimo: 300%</li>
</ul>
<h3 style="color: #004B5F;">Interpretaci√≥n de criterios:</h3>
<ul>
   <li>Recall 80%: De cada 10 clientes que abandonan, detectamos al menos 8</li>
   <li>Precisi√≥n 75%: De cada 10 alertas de abandono, 7.5 son reales</li>
   <li>ROI 3:1: Por cada $1 en retenciones, generamos $3 en ingresos preservados</li>
</ul>
<h3 style="color: #004B5F;">6. Pregunta de la investigaci√≥n: </h3>
<h3 style="color: #004B5F;">Tipo de pregunta: predictiva</h3>
<h3 style="color: #004B5F;">Pregunta principal de investigaci√≥n:</h3>
<strong>¬øCual es la probabilidad de abandono de un cliente en una empresa que brinda servicios de telecomunicaciones?</strong>
<h3 style="color: #004B5F;">7. Identificacion de la variable dependiente e independiente</h3>
<img src="prueba_tabla.png" />
<p>Se tienen 16 variables categoricas y 3 variables continuas</p>
<br/>
<h2 style="color: #259B88;">Secci√≥n 2: Determinaci√≥n de la T√©cnica Anal√≠tica  </h2>
<h3 style="color: #004B5F;">1. An√°lisis Exploratorio de Datos (EDA): </h3>
<img src="eda1.png" />
<p>A mayor antigueda disminuye la posibilidad de abandono</p>
<br/>
<img src="eda2.png" />
<p>Mientras el cargo mensual de un cliente crece la posibilidad de abandono tambien</p>
<br/>
<img src="eda3.png" />
<p>Mientras mayores son los los cargos mensuales y menor la antiguedad la probabilidad de abandono es muy alta</p>
<br/>
<img src="eda4.png" />
<p>Hay una relacion lineal entre la permanencia y la antiguedad de un cliente</p>
<br/>
<img src="correlacion.png" />
<p>La matriz de correlacion del conjunto de datos</p>
<br/>
<h3 style="color: #004B5F;">2. Clasificaci√≥n de T√©cnicas:  </h3>
<p>T√©cnica principal: REGRESI√ìN LOG√çSTICA
   <br/>
   Justificaci√≥n: Interpretabilidad, probabilidades calibradas, buen baseline
</p>
<h3 style="color: #004B5F;">3. Criterios de Selecci√≥n: </h3>
<p>T√âCNICA SELECCIONADA: REGRESI√ìN LOG√çSTICA</p>
<ul>
   <li>Mayor interpretabilidad para stakeholders de negocio</li>
   <li>Proporciona probabilidades calibradas</li>
   <li>Excelente baseline para comparaci√≥n</li>
   <li>R√°pida implementaci√≥n y debugging</li>
</ul>
<h3 style="color: #004B5F;">4. Justificaci√≥n:  </h3>
<ul>
   <li>Interpretabilidad: Coeficientes indican direcci√≥n y magnitud de efectos</li>
   <li>Probabilidades: Outputs son probabilidades calibradas [0,1]</li>
   <li>Eficiencia: Computacionalmente eficiente para datasets medianos</li>
   <li>Linealidad: Supuesto razonable para muchas relaciones negocio</li>
   <li>Baseline: Punto de referencia esencial para modelos complejos</li>   
</ul>
<h3 style="color: #004B5F;">5. Criterio de √âxito - alternativas descartadas  </h3>
<img src="tabla_comparacion.png" />
<h2 style="color: #259B88;">Secci√≥n 3: Uso de las T√©cnicas Competidoras </h2>
<h3 style="color: #004B5F;">1. Implementaci√≥n Paralela  </h3>
<img src="validacion_cruzada.png" />
<br/>
<img src="comparacion_modelos.png" />
<h3 style="color: #004B5F;">2. Documentaci√≥n de Resultados  </h3>
<img src="documentacion_resultados.png" />
<h3 style="color: #004B5F;">3. An√°lisis Preliminar  </h3>
<img src="documentacion_resultados.png" />
<ul>
   <li>Random Forest tiene recall m√°s alto pero a costa de precisi√≥n</li>
   <li>XGBoost muestra mejor AUC pero F1-Score similar a Regresi√≥n Log√≠stica</li>
   <li>La diferencia en performance no justifica complejidad adicional inicialmente</li>
</ul>
<h3 style="color: #004B5F;">4. Criterio de √âxito  </h3>
<img src="comparacion_metricas.png" />
   
<div class="code-container">
<pre><code class="language-python">
# IMPLEMENTACI√ìN PARALELA DE T√âCNICAS
import pandas as pd
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.model_selection import cross_val_score, StratifiedKFold
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.model_selection import train_test_split

print("="*60)
print("IMPLEMENTACI√ìN PARALELA DE T√âCNICAS")
print("="*60)

df_model = pd.read_csv('Telco-Customer-Churn.csv')

# Limpieza de datos: convertir espacios vac√≠os a NaN y eliminar o imputar
df_model['TotalCharges'] = pd.to_numeric(df_model['TotalCharges'], errors='coerce')
df_model = df_model.dropna()  # Eliminar filas con valores NaN

# Preparaci√≥n de datos
df_model = df_model.drop('customerID', axis=1)

# Inicializar LabelEncoder para cada columna (no reutilizar)
le = LabelEncoder()

# Codificar variables categ√≥ricas
categorical_columns = ['gender', 'Partner', 'Dependents', 'PhoneService', 
                      'MultipleLines', 'InternetService', 'OnlineSecurity', 
                      'OnlineBackup', 'DeviceProtection', 'TechSupport', 
                      'StreamingTV', 'StreamingMovies', 'Contract', 
                      'PaperlessBilling', 'PaymentMethod', 'Churn']

for col in categorical_columns:
    df_model[col] = le.fit_transform(df_model[col].astype(str))

X = df_model.drop('Churn', axis=1)
y = df_model['Churn']

# Divisi√≥n train-test
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Estandarizaci√≥n para Regresi√≥n Log√≠stica
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Configuraci√≥n de validaci√≥n cruzada
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# Modelos
modelos = {
    'Regresi√≥n Log√≠stica': LogisticRegression(random_state=42, max_iter=1000),
    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),
    'XGBoost': XGBClassifier(random_state=42, eval_metric='logloss')
}

# Entrenamiento y evaluaci√≥n
resultados = {}

for nombre, modelo in modelos.items():
    print(f"\nüîß ENTRENANDO: {nombre}")
    
    # Seleccionar datos escalados o no
    if nombre == 'Regresi√≥n Log√≠stica':
        X_tr = X_train_scaled
        X_te = X_test_scaled
    else:
        X_tr = X_train
        X_te = X_test
    
    # Entrenar modelo
    modelo.fit(X_tr, y_train)
    
    # Predecir
    y_pred = modelo.predict(X_te)
    y_pred_proba = modelo.predict_proba(X_te)[:, 1] if hasattr(modelo, "predict_proba") else [0]*len(y_test)
    
    # M√©tricas
    resultados[nombre] = {
        'Accuracy': accuracy_score(y_test, y_pred),
        'Precision': precision_score(y_test, y_pred, zero_division=0),
        'Recall': recall_score(y_test, y_pred, zero_division=0),
        'F1-Score': f1_score(y_test, y_pred, zero_division=0),
        'AUC-ROC': roc_auc_score(y_test, y_pred_proba) if len(np.unique(y_test)) > 1 else 0.5
    }
    
    # Validaci√≥n cruzada
    cv_scores = cross_val_score(modelo, X_tr, y_train, cv=cv, scoring='f1')
    resultados[nombre]['CV_F1_Mean'] = cv_scores.mean()
    resultados[nombre]['CV_F1_Std'] = cv_scores.std()
    
    print(f"   Entrenamiento completado")
    print(f"   F1-Score: {resultados[nombre]['F1-Score']:.4f}")
    print(f"   AUC-ROC: {resultados[nombre]['AUC-ROC']:.4f}")

# Mostrar resultados comparativos
print("\n" + "="*60)
print("COMPARACI√ìN DE MODELOS")
print("="*60)
for modelo, metrics in resultados.items():
    print(f"\n{modelo}:")
    for metric, value in metrics.items():
        print(f"  {metric}: {value:.4f}")
</code></pre>
</div>

<!-- Script de Prism.js -->
<script src=https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/components/prism-python.min.js></script>
 <img src="variables_aumenta_disminuyen.png" />
    <p>El aporte que hace cada variable al modelo</p>
    <br/>

    <h2 style="color: #259B88;">Secci√≥n 4: Comparaci√≥n en T√©rminos de un Criterio Preciso </h2>
    <h3 style="color: #004B5F;">1. Definicion de Criterio Preciso  </h3>
    <p> Considerando que se tienen prioridad de detectar el MAXIMO de abandonos reales. </p>   
    <b>Criterio preciso seleccionado</b>
    <ul>
        <li>Balance entre Recall (evitar perder clientes) y Precision (no malgastar recursos)</li>
        <li>M√©trica robusta para problemas desbalanceados</li>
        <li>Alineado con objetivo de maximizar ROI en campa√±as de retenci√≥n</li>
    </ul>
    <p>Configuracion de validacion cruzada</p>
    <ul>
        <li>Estratificada: Mantiene proporci√≥n de clases en cada fold</li>
        <li>10 folds: Mayor robustez en estimaci√≥n de performance, k = 10</li>
        <li>3 repeticiones: Reducir variabilidad del sampling</li>
    </ul>    
    <h3 style="color: #004B5F;">2. Comparaci√≥n con Pruebas Estad√≠sticas</h3>
    <img src="estadisticos_1.png" />
    <h3 style="color: #004B5F;">3. Visualizaci√≥n</h3>
    <table>
        <tbody>
            <tr>
                <td><img src="vi_1.png" /></td>
                <td><img src="vi_2.png" /></td>
                <td><img src="vi_3.png" /></td>                
            </tr>
            <tr>
                <td>El F1 Score se encuentra en un rango de valores superior con un valor medio de 59.8%</td>
                <td>La regresion logistica es la que alcanza mejores resultados respecto a las metricas</td>
                <td>Random Forest vs XGBoost: p = 0.518590 √ó NO SIGNIFICATIVO</td>                
            </tr>
            <tr> 
                <td></td>
                <td></td>
                <td></td>       
            </tr>
            <tr>
                <td><img src="vi_4.png" /></td>
                <td><img src="vi_5.png" /></td>   
                <td></td>
            </tr>
            <tr>
                <td>Random forest alcanza un 100% en cuanto a AUC</td>
                <td>XGBoost es el que tiene el mejor CV F1-Score</td>
                <td></td>                
            </tr>
        </tbody>
    </table>    
    <h3 style="color: #004B5F;">4. Interpretaci√≥n  </h3>
    <ul>
        <li>Clientes totales: 7,043</li>
        <li>Tasa de abandono mensual: 26.54%</li>
        <li>Clientes que abandonan mensualmente: 1869</li>
        <li>Ingreso promedio mensual: $64.76</li>
        <li>Valor anual por cliente: $777.14</li>
        <li>Costo campa√±a retenci√≥n por cliente: $50</li>
    </ul>
    <strong>RANDOM FOREST:</strong> 
    <ul>
        <li>Recall: 48.8% ‚Üí Detecta 912 de 1869 abandonos reales</li>
        <li>Clientes a contactar: 1643 (incluye 731 falsos positivos)</li>
        <li>Costo campa√±a: $82,155</li>
        <li>Ingresos preservados: $59,061</li>
        <li>ROI: -0.3x ($-23,093 neto)</li>
    </ul>
    <strong>REGRESI√ìN LOG√çSTICA:</strong> 
    <ul>
        <li>Recall: 51.4% ‚Üí Detecta 961 de 1869 abandonos reales</li>
        <li>Clientes a contactar: 1720 (incluye 759 falsos positivos)</li>
        <li>Costo campa√±a: $86,003</li>
        <li>Ingresos preservados: $62,235</li>
        <li>ROI: -0.3x ($-23,768 neto)</li>
    </ul>
    <strong>AN√ÅLISIS:</strong> 
    <ul>
        <li>Regresi√≥n Log√≠stica: Alcanza un mejor balance general y por naturaleza posee una interpretabilidad superior</li>
        <li>Random Forest: Presenta un mayor recall y una menor precisi√≥n, sin embargo es m√°s costoso</li>
        <li>XGBoost: Posee un mejor AUC y en contrapartida presenta una complejidad operacional</li>        
    </ul>
    <h3 style="color: #004B5F;">5. Criterio de √âxito:</h3>
    <img src="tabla_comparativa.png" />
    <br/>
    <strong>RESUMEN ESTAD√çSTICO:</strong> 
    <ul>
        <li>Mejor modelo: Regresi√≥n Log√≠stica (F1: 0.5981)</li>
        <li>Segundo mejor: XGBoost (F1: 0.5587)</li>
        <li>Diferencia: 0.0394</li>
        <li>Significancia estad√≠stica: p = 0.000000</li>        
    </ul>
     <strong>CRITERIOS SECUNDARIOS DE DECISI√ìN:</strong> 
    <ul>
        <li>Interpretabilidad: Regresi√≥n Log√≠stica (Coeficientes explicables)</li>
        <li>Velocidad inferencia: Regresi√≥n Log√≠stica (M√°s r√°pido en producci√≥n)</li>
        <li>Robustez outliers: Random Forest (Menos sensible a valores extremos)</li>
        <li>Performance crudo: XGBoost (Mejor AUC en algunos casos)</li>        
    </ul>
   
    <img src="comparacion_final.png" />
    <br/>
    <strong>MODELO GANADOR RECOMENDADO: REGRESI√ìN LOG√çSTICA</strong> 
    <ul>
        <li>F1-Score: 0.5981</li>
        <li>Recall: 0.5509</li>
        <li>Estabilidad: 0.0447</li>        
    </ul>
    <h2 style="color: #259B88;">Secci√≥n 5: Optimizaci√≥n en T√©rminos de Criterio Preciso o Inadecuado</h2>
    <h3 style="color: #004B5F;">1. Optimizaci√≥n Precisa</h3>
    <strong>MEJORES HIPERPAR√ÅMETROS ENCONTRADOS:</strong> 
    <ul>
        <li>C: 10</li>
        <li>class_weight: balanced</li>
        <li>max_iter: 1000</li>
        <li>penalty: l1</li>        
        <li>solver: liblinear</li>        
        <li>Mejor F1-Score (CV): 0.6342</li>        
    </ul>
    <img src="curva_aprendizaje.png" />
    <br/>     
    <h3 style="color: #004B5F;">2. Incorporacion de Criterios Inadecuados</h3>
    <strong>AN√ÅLISIS DE TIEMPO DE INFERENCIA:</strong> 
    <ul>
        <li>Modelo Base: 1.1490s para 10000 inferencias</li>
        <li>Modelo Optimizado: 1.0770s para 10000 inferencias</li>
        <li>Diferencia: -0.0720s</li>        
    </ul>
    <strong>AN√ÅLISIS DE INTERPRETABILIDAD:</strong> 
    <ul>
        <li>Tiempo permanencia: DISMINUYE probabilidad de abandono (coef: -1.2396)</li>
        <li>Cargos mensuales: AUMENTA probabilidad de abandono (coef: 0.6893)</li>
        <li>Tipo de contrato: DISMINUYE probabilidad de abandono (coef: -0.6606)</li>
        <li>Cargos totales: AUMENTA probabilidad de abandono (coef: 0.5867)</li>
        <li>Servicio Telefonico (S/N): DISMINUYE probabilidad de abandono (coef: -0.3003)</li>
        <li>Seguridad en Linea (S/N): DISMINUYE probabilidad de abandono (coef: -0.2443)</li>
        <li>Soporte Tecnico (S/N): DISMINUYE probabilidad de abandono (coef: -0.2273)</li>
        <li>Servicio de Internet (Fibra/DSL): AUMENTA probabilidad de abandono (coef: 0.1606)</li>
        <li>Facturacion sin Papel: AUMENTA probabilidad de abandono (coef: 0.1393)</li>
        <li>Copia de Seguridad en Linea: DISMINUYE probabilidad de abandono (coef: -0.1361)</li>
    </ul>
     <h3 style="color: #004B5F;">3. Iteraci√≥n y validacion final </h3>
    <strong>VERIFICACI√ìN CRITERIO PRECISO (5% MEJORA)</strong> 
    <ul>
        <li>F1-Score Inicial: 0.5927</li>
        <li>Mejora Total Alcanzada: +68.72%</li>
        <li>Diferencia: Objetivo 5%: SUPERADO</li>        
    </ul>
    <strong>RESUMEN EJECUTIVO FINAL</strong> 
    <ul>
        <li>T√âCNICA OPTIMIZADA: Regresi√≥n Log√≠stica</li>
        <li>MEJORA F1-SCORE: +68.72% (de 0.5927 a 1.0000)</li>
        <li>CARACTER√çSTICAS SELECCIONADAS: 15 de 24 originales</li>        
    </ul>
    <img src="matriz de confusion.png" />
        <p>La matriz de confusion del modelo final</p>
    <br/>
    <img src="journey.png" />
        <p>El rendimiento del modelo alcanzado con ajustes de ingenieria</p>
  </body>

</html>
