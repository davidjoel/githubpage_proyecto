

<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <title>Ejemplo PySpark</title>
    <!-- Estilos b√°sicos -->
    <style>
        body {
            font-family: Arial, sans-serif;
            background: #f4f4f4;
            padding: 20px;
        }
        .code-container {
            background: #2d2d2d;
            color: #f8f8f2;
            padding: 15px;
            border-radius: 8px;
            overflow-x: auto;
            font-size: 14px;
            line-height: 1.5;
        }
        pre {
            margin: 0;
        }
    </style>
    <!-- Librer√≠a Prism.js para resaltado -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel<h1>Ejemplo de c√≥digo PySpark</h1>
</head>
   
<h1 style="color: #259B88;"> Telco Customer Churn </h1>
<h2 style="color: #259B88;"> Secciones del Sprint 1 </h2>
<h2 style="color: #259B88;">Secci√≥n 1: Definici√≥n del Problema </h2>
<h3 style="color: #004B5F;">1. Identificar el Problema de Negocio: </h3>
<h4 style="color: #004B5F;">Contexto del problema:</h4>
<ul>
   <li>Total de clientes: 7,043</li>
   <li>Tasa de churn actual: 26.54%</li>
   <li>Ingreso promedio mensual por cliente: $64.76</li>
   <li>P√©rdida anual estimada: $1,452,475.24</li>
   <li>Clientes que abandonan mensualmente: 1869</li>
</ul>
<h4 style="color: #004B5F;">Impacto:</h4> 
<strong>
‚ÄúLa empresa enfrenta una rotaci√≥n del 26.5% de su base de clientes, esto representa una p√©rdida anual estimada de $1,452,475.24 y de aqu√≠ es que surge la necesidad cr√≠tica de implementar estrategias de fidelizaci√≥n de clientes‚Äù   
</strong>
<h3 style="color: #004B5F;">2. Establecer Objetivos Anal√≠ticos:</h3>
<ul>
   <li>Predecir clientes con alta probabilidad de abandono en los pr√≥ximos 30 d√≠as</li>
   <li>Alcanzar recall del 80% y precisi√≥n del 75% en la detecci√≥n de churn</li>
   <li>Utilizando datos hist√≥ricos de comportamiento y contratos</li>
   <li>Reducir la tasa de churn en al menos 15% en 6 meses</li>
   <li>Implementar el modelo en producci√≥n en 8 semanas</li>
</ul>

<h3 style="color: #004B5F;">3. Delimitar el Alcance: </h3>
<h4 style="color: #004B5F;">Variables objetivo:</h4>
<ul>
   <li>Variable dependiente: Churn (binaria - Yes/No)</li>
   <li>Horizonte temporal: Pr√≥ximos 30 d√≠as</li>
</ul>
<h4 style="color: #004B5F;">Variables predictoras disponibles:</h4>
<ul>
   <li><b><span style="color: #259B88;">Demogr√°ficas:</span></b> 4 variables</li>
   <li><b><span style="color: #259B88;">Servicios:</span></b> 4 variables</li>
   <li><b><span style="color: #259B88;">Contrato y facturaci√≥n:</span></b> 6 variables</li>
</ul>
<h4 style="color: #004B5F;">Restricciones identificadas:</h4>
<ul>
   <li><b><span style="color: #259B88;">√âticas:</span></b> Datos anonimizados, sin informaci√≥n personal sensible</li>
   <li><b><span style="color: #259B88;">T√©cnicas:</span></b> Python, scikit-learn, 8GB RAM m√≠nimo y 16 GB de RAM ideal</li>
   <li><b><span style="color: #259B88;">Temporales:</span></b> 4 semanas para desarrollo del modelo</li>
   <li><b><span style="color: #259B88;">Datos:</span></b> Dataset balanceado artificialmente para entrenamiento</li>
</ul>
<h3 style="color: #004B5F;">4. Formular Hip√≥tesis Iniciales:</h3>
<h4 style="color: #004B5F;">Hip√≥tesis principales:</h4>
<ol>
   <li>
        H1: Los clientes con contratos mensuales tienen 3 veces mayor probabilidad de abandono que los de contratos anuales    
   </li>
   <li>
        H2: La falta de servicios de seguridad online incrementa en 40% la probabilidad de abandono    
   </li>
   <li>
        H3: Los clientes con menos de 12 meses de antig√ºedad representan el 50% del total de abandonos    
   </li>
   <li>
      H4: El m√©todo de pago electr√≥nico reduce en 25% la probabilidad de abandono      
   </li>
</ol>
<h3 style="color: #004B5F;">5. Criterio de √âxito:</h3>
<h3 style="color: #004B5F;">Criterios de √©xito del modelo:</h3>
<ul>
   <li>Recall: 0.80</li>
   <li>Precision: 0.75</li>
   <li>AUC-ROC: 0.85</li>
   <li>F1-Score: 0.77</li>
   <li>Reducci√≥n_churn: 15%</li>
   <li>ROI_minimo: 300%</li>
</ul>
<h3 style="color: #004B5F;">Interpretaci√≥n de criterios:</h3>
<ul>
   <li>Recall 80%: De cada 10 clientes que abandonan, detectamos al menos 8</li>
   <li>Precisi√≥n 75%: De cada 10 alertas de churn, 7.5 son reales</li>
   <li>ROI 3:1: Por cada $1 en retenciones, generamos $3 en ingresos preservados</li>
</ul>
<h3 style="color: #004B5F;">6. Pregunta de la investigaci√≥n: </h3>
<h3 style="color: #004B5F;">Tipo de pregunta: predictiva</h3>
<h3 style="color: #004B5F;">Pregunta principal de investigaci√≥n:</h3>
<strong>¬øPodemos predecir qu√© clientes tienen alta probabilidad de abandonar el servicio
    en los pr√≥ximos 30 d√≠as, utilizando sus caracter√≠sticas demogr√°ficas, de contrato,
    servicios contratados y patrones de facturaci√≥n?</strong>
<h3 style="color: #004B5F;">7. Identificacion de la variable dependiente e independiente</h3>
<img src="prueba_tabla.png" />
   
<h2 style="color: #259B88;">Secci√≥n 2: Determinaci√≥n de la T√©cnica Anal√≠tica  </h2>
<h3 style="color: #004B5F;">1. An√°lisis Exploratorio de Datos (EDA): </h3>
<img src="eda1.png" />
<br/>
<img src="eda2.png" />
<br/>
<img src="eda3.png" />
<br/>
<img src="eda4.png" />
<br/>
<h3 style="color: #004B5F;">2. Clasificaci√≥n de T√©cnicas:  </h3>
<p>T√©cnica principal: REGRESI√ìN LOG√çSTICA
   <br/>
   Justificaci√≥n: Interpretabilidad, probabilidades calibradas, buen baseline
</p>
<h3 style="color: #004B5F;">3. Criterios de Selecci√≥n: </h3>
<p>T√âCNICA SELECCIONADA: REGRESI√ìN LOG√çSTICA</p>
<ul>
   <li>Mayor interpretabilidad para stakeholders de negocio</li>
   <li>Proporciona probabilidades calibradas</li>
   <li>Excelente baseline para comparaci√≥n</li>
   <li>R√°pida implementaci√≥n y debugging</li>
</ul>
<h3 style="color: #004B5F;">4. Justificaci√≥n:  </h3>
<ul>
   <li>Interpretabilidad: Coeficientes indican direcci√≥n y magnitud de efectos</li>
   <li>Probabilidades: Outputs son probabilidades calibradas [0,1]</li>
   <li>Eficiencia: Computacionalmente eficiente para datasets medianos</li>
   <li>Linealidad: Supuesto razonable para muchas relaciones negocio</li>
   <li>Baseline: Punto de referencia esencial para modelos complejos</li>   
</ul>
<h3 style="color: #004B5F;">5. Criterio de √âxito - alternativas descartadas  </h3>
<img src="tabla_comparacion.png" />
<h2 style="color: #259B88;">Secci√≥n 3: Uso de las T√©cnicas Competidoras </h2>
<h3 style="color: #004B5F;">1. Implementaci√≥n Paralela  </h3>
<img src="validacion_cruzada.png" />
<br/>
<img src="comparacion_modelos.png" />
<h3 style="color: #004B5F;">2. Documentaci√≥n de Resultados  </h3>
<img src="documentacion_resultados.png" />
<h3 style="color: #004B5F;">3. An√°lisis Preliminar  </h3>
<img src="documentacion_resultados.png" />
<ul>
   <li>Random Forest tiene recall m√°s alto pero a costa de precisi√≥n</li>
   <li>XGBoost muestra mejor AUC pero F1-Score similar a Regresi√≥n Log√≠stica</li>
   <li>La diferencia en performance no justifica complejidad adicional inicialmente</li>
</ul>
<h3 style="color: #004B5F;">4. Criterio de √âxito  </h3>
<img src="comparacion_metricas.png" />
   
<div class="code-container">
<pre><code class="language-python">
# IMPLEMENTACI√ìN PARALELA DE T√âCNICAS
import pandas as pd
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.model_selection import cross_val_score, StratifiedKFold
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.model_selection import train_test_split

print("="*60)
print("IMPLEMENTACI√ìN PARALELA DE T√âCNICAS")
print("="*60)

df_model = pd.read_csv('Telco-Customer-Churn.csv')

# Limpieza de datos: convertir espacios vac√≠os a NaN y eliminar o imputar
df_model['TotalCharges'] = pd.to_numeric(df_model['TotalCharges'], errors='coerce')
df_model = df_model.dropna()  # Eliminar filas con valores NaN

# Preparaci√≥n de datos
df_model = df_model.drop('customerID', axis=1)

# Inicializar LabelEncoder para cada columna (no reutilizar)
le = LabelEncoder()

# Codificar variables categ√≥ricas
categorical_columns = ['gender', 'Partner', 'Dependents', 'PhoneService', 
                      'MultipleLines', 'InternetService', 'OnlineSecurity', 
                      'OnlineBackup', 'DeviceProtection', 'TechSupport', 
                      'StreamingTV', 'StreamingMovies', 'Contract', 
                      'PaperlessBilling', 'PaymentMethod', 'Churn']

for col in categorical_columns:
    df_model[col] = le.fit_transform(df_model[col].astype(str))

X = df_model.drop('Churn', axis=1)
y = df_model['Churn']

# Divisi√≥n train-test
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Estandarizaci√≥n para Regresi√≥n Log√≠stica
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Configuraci√≥n de validaci√≥n cruzada
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# Modelos
modelos = {
    'Regresi√≥n Log√≠stica': LogisticRegression(random_state=42, max_iter=1000),
    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),
    'XGBoost': XGBClassifier(random_state=42, eval_metric='logloss')
}

# Entrenamiento y evaluaci√≥n
resultados = {}

for nombre, modelo in modelos.items():
    print(f"\nüîß ENTRENANDO: {nombre}")
    
    # Seleccionar datos escalados o no
    if nombre == 'Regresi√≥n Log√≠stica':
        X_tr = X_train_scaled
        X_te = X_test_scaled
    else:
        X_tr = X_train
        X_te = X_test
    
    # Entrenar modelo
    modelo.fit(X_tr, y_train)
    
    # Predecir
    y_pred = modelo.predict(X_te)
    y_pred_proba = modelo.predict_proba(X_te)[:, 1] if hasattr(modelo, "predict_proba") else [0]*len(y_test)
    
    # M√©tricas
    resultados[nombre] = {
        'Accuracy': accuracy_score(y_test, y_pred),
        'Precision': precision_score(y_test, y_pred, zero_division=0),
        'Recall': recall_score(y_test, y_pred, zero_division=0),
        'F1-Score': f1_score(y_test, y_pred, zero_division=0),
        'AUC-ROC': roc_auc_score(y_test, y_pred_proba) if len(np.unique(y_test)) > 1 else 0.5
    }
    
    # Validaci√≥n cruzada
    cv_scores = cross_val_score(modelo, X_tr, y_train, cv=cv, scoring='f1')
    resultados[nombre]['CV_F1_Mean'] = cv_scores.mean()
    resultados[nombre]['CV_F1_Std'] = cv_scores.std()
    
    print(f"   Entrenamiento completado")
    print(f"   F1-Score: {resultados[nombre]['F1-Score']:.4f}")
    print(f"   AUC-ROC: {resultados[nombre]['AUC-ROC']:.4f}")

# Mostrar resultados comparativos
print("\n" + "="*60)
print("COMPARACI√ìN DE MODELOS")
print("="*60)
for modelo, metrics in resultados.items():
    print(f"\n{modelo}:")
    for metric, value in metrics.items():
        print(f"  {metric}: {value:.4f}")
</code></pre>
</div>

<!-- Script de Prism.js -->
https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/components/prism-python.min.js</script>


    <h2 style="color: #259B88;">Secci√≥n 4: Comparaci√≥n en T√©rminos de un Criterio Preciso </h2>
    <h3 style="color: #004B5F;">1. Definicion de Criterio Preciso  </h3>
    <p> Considerando que se tienen prioridad de detectar el MAXIMO de abandonos reales </p>   
        
</body>
</html>
